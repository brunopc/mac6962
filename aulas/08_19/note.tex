\section{Aula 19 de Agosto de 2019}
\label{2019_08_19}

Esta nota de aula foi escrita por Vitor Santa Rosa Gomes, seguindo o conteúdo apresentado em aula por Yoshiharu Kohayakawa, com base principalmente no capítulo 5 de \cite[p.~129]{blum_hopcroft}, iniciado na aula anterior. As interpretações dadas são compiladas por Vitor podem não podem ser consideradas citações nem de Kohayakawa, nem de \cite{blum_hopcroft}.

%region recapitulating
\subsection*{Relembrando conceitos do Aprendizado de Máquina}

Algoritmos de \textit{Aprendizado de Máquina} (ML) são ferramentas que permitem generalizar estruturas a partir de dados, sem conhecimento detalhado sobre o domínio. Um dos problemas fundamentais em ML é aprender a classificar bem dados rotulados em \textit{classes} ou \textit{categorias} --- chamados de \textit{Problemas de Classificação}. Tipicamente, consideramos um \textit{espaço de instâncias} $\mathcal{X}$ --- com $\mathcal{X}=\left\{0,\ 1\right\}^d$ ou $\mathcal{X}=\mathds{R}^d$ ---, correspondendo a dados com $d$ \text{descritores}, \text{dimensões} ou \text{features}. Para abordar esse problema, usa-se um \textit{conjunto de treinamento} $\mathrm{S}\subseteq\mathcal{X}$ corretamente rotulado, a fim de \textit{generalizar} nosso conhecimento inferido de $\mathrm{S}$ para $\mathcal{X}$.

Para afirmar garantias da capacidade de generalização dos algoritmos de ML, é necessário assumir que (1) $\mathrm{S}$ é uma boa representação de $\mathcal{X}$, e que (2) as regras usadas pelos algoritmos são ``simples'' de alguma forma. Mais formalmente, seja $\mathcal{D}\colon\ \mathcal{X}\mapsto\mathds{R}$ uma distribuição de probabilidade sobre $\mathcal{X}$ tal que $\mathrm{S}$ é amostrado uniforme e independentemente (i.i.d) em $\mathcal{D}$; nosso objetivo é fazer boas afirmações sobre novos pontos tomados em $\mathcal{D}$. Quando há apenas duas classes, definição das categorias é feita por um \textit{conceito objetivo} $c^\star\subseteq\mathcal{X}$ --- isto é, $c^\star$ e ${c^\star}^\complement$ particionam $\mathcal{X}$ nas duas classes. Finalmente, o propósito está em encontrar uma \textit{hipótese} $h\subseteq\mathcal{X}$ que seja próxima de $c^\star$ com respeito à distribuição $\mathcal{D}$. Uma métrica para verificar essa proximidade é o \textit{erro de generalização}
\[
  \mathrm{err}_\mathcal{D}\left(h\vphantom{1j}\right)=\mathrm{P}\left[h\mathrel{\Delta}c^\star\vphantom{1j}\right],
\]
sendo que o operador $\Delta$ é a \textit{diferença simétrica}
\[
  h\mathrel{\Delta}c^\star\vcentcolon=\left(h\setminus c^\star\vphantom{1j}\right)\cup\left(c^\star\setminus h\vphantom{1j}\right).
\]
Interpreta-se $\mathrm{err}_\mathcal{D}$ como a probabilidade de classificar incorretamente com $h$ um ponto tomado aleatoriamente de $\mathcal{D}$. Uma forma de estimá-lo é usar o \textit{erro de treinamento}
\[
  \mathrm{err}_\mathrm{S}=\nicefrac{\left|\left(h\mathrel{\Delta}c^\star\vphantom{1j}\right)\cap\mathrm{S}\vphantom{1j}\right|}{\left|\mathrm{S}\vphantom{1j}\right|}.
\]

Mesmo que $\mathrm{S}$ seja representativo de $\mathcal{X}$, um algoritmo que apenas memorize $\mathrm{S}$ costuma ter $\mathrm{err}_\mathrm{S}\mathcal{L}\mathrm{err}_\mathcal{D}$, evento conhecimento como \textit{overfitting}. A fim de analisar a diferença esperada entre o erro de treinamento e o erro de generalização, define-se uma \textit{classe de hipóteses} $\mathcal{H}\subseteq 2^\mathcal{X}$, com $h\in\mathcal{H}$ que impõe um limite de complexidade sobre $h$. A motivação de que $h$ seja simples é garantir que $\mathrm{err}_\mathrm{S}\approx\mathrm{err}_\mathcal{D}$.

Vimos na aula passada a motivação e a prova dos teoremas \autoref{teo:pac} e \autoref{teo:convergencia_uniforme}.

\begin{definicao}
  Uma hipótese $h\in\mathcal{H}$ é $\left(\mathrm{S},\ \eps\vphantom{1j}\right)\!\text{-ruim}$ se $\mathrm{err}_\mathrm{S}\left(h\vphantom{1j}\right)=0$, mas $\mathrm{err}_\mathcal{D}\left(h\vphantom{1j}\right)>\eps$.
\end{definicao}

\begin{teorema}[Provavelmente Aproximadamente Correto]
  \label{teo:pac}
  Seja $\mathcal{H}$ uma classe de hipóteses, e sejam $\eps$ e $\delta$ positivos. Se um conjunto de treinamento $\mathrm{S}$ com tamanho
  \[
    n \coloneqq \left|\mathrm{S}\vphantom{1j}\right| \geq \frac{1}{\eps}\cdot\left(\log\left|\mathcal{H}\vphantom{1j}\right| + \log\nicefrac{1}{\delta}\vphantom{1j}\right),
  \]
  é amostrado da distribuição $\mathcal{D}$ dos dados $\mathcal{X}$, então
  \[
    \mathrm{P}\left(\exists h\in\mathcal{H}\colon\ \left(\mathrm{S},\ \eps\vphantom{1j}\right)\!\text{-ruim}\vphantom{1j}\right) \leq \delta.
  \]
\end{teorema}

\begin{teorema}[Convergência Uniforme]
  \label{teo:convergencia_uniforme}
  Seja $\mathcal{H}$ uma classe de hipóteses, e sejam $\eps$ e $\delta$ positivos. Se um conjunto de treinamento $\mathrm{S}$ com tamanho
  \[
    n \coloneqq \left|\mathrm{S}\vphantom{1j}\right| \geq \frac{1}{2\cdot\eps^2}\cdot\left(\log\left|\mathcal{H}\vphantom{1j}\right| + \log\nicefrac{2}{\delta}\vphantom{1j}\right),
  \]
  é amostrado da distribuição $\mathcal{D}$ dos dados $\mathcal{X}$, então
  \[
    \mathrm{P}\left[\left|\mathrm{err}_\mathrm{S}\left(h\vphantom{1j}\right)-\mathrm{err}_\mathcal{D}\left(h\vphantom{1j}\right)\vphantom{1j}\right| > \eps\vphantom{1j}\right] \leq \delta.
  \]
\end{teorema}
%endregion

%region occam's razor
\subsection{Navalha de Occam}

Na filosofia, é comum tratar objetos em função dos mesmos, como pensar sobre o auto de pensar, por isso são usadas diversas técnicas práticas ou \textit{argumentos de corte} com intuito de ``podar a árvore de recursão'', numa interpretação mais computacional. Como sugestão de leitura sobre esses métodos , há <\href{https://en.wikipedia.org/wiki/Philosophical\_razor}{https://en.wikipedia.org/wiki/Philosophical\_razor}>.

Em particular, pela \textit{Navalha de Occam} --- declarada por William Occam por volta de 1320 antes de Cristo ---, ``explicações simples dos fenômenos observados são mais prováveis de estarem corretas; busca-se evitar explicações improváveis''. Embora essa afirmação não possua qualquer validade formal, é uma regra que funciona bem na prática. Ainda assim, os teoremas \autoref{teo:pac} e \autoref{teo:convergencia_uniforme} podem ser vistos como casos especiais da Navalha de Occam, dadas suas fortes, necessárias e normalmente irreais hipóteses.

\begin{afirmacao}
  \label{afr:navalha_de_occam}
  Damos preferência a conceitos ou hipóteses simples, em detrimento de mais complicadas.
\end{afirmacao}

Ainda assim, é possível formalizar o conceito de ``simples'' dentro de Ciência da Computação com \textit{linguagens de descrição} da seguinte forma:
\begin{teorema}
  \label{teo:navalha_de_occam}
  Dada uma linguagem de descrição $\mathcal{L}$, seja $b\coloneqq\#\mathrm{bits}\left(h\vphantom{1j}\right)$ a quantidade de bits usados para especificar uma hipótese $h\in\mathcal{H}$ em $\mathcal{L}$.

  Defina
  \[
    \mathcal{L}_b\coloneqq\left\{h\in\mathcal{H}\colon\ \mathrm{size}\left(h\vphantom{1j}\right)=b\vphantom{1j}\right\}
  \]
  e
  \[ 
    \mathcal{L}_{<b} = \bigcup_{b'<b} \mathcal{L}_b.
  \]

  Fixe $\eps$ e $\delta$ positivos, e seja um conjunto de treinamento $\mathrm{S}$ com tamanho
  \[
    n \coloneqq \left|\mathrm{S}\vphantom{1j}\right| \geq \frac{1}{\eps}\cdot\left(b\cdot\log2 + \log\nicefrac{1}{\delta}\vphantom{1j}\right).
  \]
  Então
  \[
    \mathrm{P}\left[\exists h\in\mathcal{H}\colon\ \left(\mathrm{S},\ \eps\vphantom{1j}\right)\text{-ruim}\vphantom{1j}\right] \leq \delta
  \]

  Equivalentemente, com probabilidade pelo menos $1-\delta$, se $\mathrm{err}_\mathcal{S}\left(h\vphantom{1j}\right)$ e $h\in\mathcal{L}_{<b}$, então
  \[
    \mathrm{err}_\mathcal{D}\left(h\vphantom{1j}\right) \leq \frac{b\cdot\log2 + \log\nicefrac{1}{\delta}}{\left|\mathrm{S}\vphantom{1j}\right|}.
  \]
\end{teorema}

\begin{observacao}
  Pela construção de $\mathcal{L}_b$, sabemos que
  \begin{itemize}
    \item $\left|\mathcal{L}_b\vphantom{1j}\right| \leq 2^b$
    \item $\left|\mathcal{L}_{<b}\vphantom{1j}\right| \leq 1 + 2 + \ldots + 2^{b-1} < 2^b$
  \end{itemize}
\end{observacao}

\begin{exemplo}
  Essa representação de hipóteses em bits é bastante clara quando $\mathcal{X}=\left\{0,\ 1\right\}^d$ e $c^\star$ pode ser expresso como:
  \begin{itemize}
    \item Quando $c^\star$ é uma disjunção das features, basta que $\mathcal{L}=\left\{0,\ 1\vphantom{1j}\right\}^d$, com hipóteses no formato $h\left(x_1,\ \ldots,\ x_d\vphantom{1j}\right)=x_2\lor x_5\lor x_7$.
    \item Quando $c^\star$ é uma função booleana (ou circuito lógico) das features, basta que $\mathcal{L}=\left\{\text{árvores de decisão}\vphantom{1j}\right\}=\left\{\text{circuitos booleanos}\vphantom{1j}\right\}$. com hipóteses no formato $\mathcal{H}=\left\{\text{funções booleanas}\vphantom{1j}\right\}$, $h\colon\ \left\{0,\ 1\vphantom{1j}\right\}^d\mapsto\left\{-1,\ 1\vphantom{1j}\right\}$.
  \end{itemize}
\end{exemplo}

É possível modificar o Teorema da Convergência Uniforme \autoref{teo:convergencia_uniforme} para incluir linguagens de descrição:

\begin{corolario}
  \label{cor:convergencia_uniforme_bits}
  Seja $\mathcal{H}$ uma classe de hipóteses, e sejam $\eps$ e $\delta$ positivos. Se (1) um conjunto de treinamento $\mathrm{S}$ com tamanho
  \[
    n \coloneqq \left|\mathrm{S}\vphantom{1j}\right| \geq \frac{1}{2\cdot\eps^2}\cdot\left(\log\left|\mathcal{H}\vphantom{1j}\right| + \log\nicefrac{2}{\delta}\vphantom{1j}\right),
  \]
  é amostrado da distribuição $\mathcal{D}$ dos dados $\mathcal{X}$ e se (2) a hipótese $h\in\mathcal{H}$ pode ser descrita numa linguagem $\mathcal{L}_{<b}$, então com probabilidade pelo menos $1-\delta$
  \[
    \mathrm{err}_\mathcal{D}\left(h\vphantom{1j}\right) \leq \mathrm{err}_\mathrm{S}\left(h\vphantom{1j}\right) + \eps.
  \]

  Equivalentemente, por manipulação algébrica,
  \[
    \mathrm{err}_\mathcal{D}\left(h\vphantom{1j}\right) \leq \mathrm{err}_\mathrm{S}\left(h\vphantom{1j}\right) + \sqrt{\frac{1}{2\cdot\left|\mathrm{S}\vphantom{1j}\right|}\cdot\left(b\cdot\log2 + \log\nicefrac{2}{\delta}\vphantom{1j}\right)}.
  \]
\end{corolario}

Nos Teoremas \autoref{teo:convergencia_uniforme} e \autoref{cor:convergencia_uniforme_bits}, $b$ é fixo. Se quisermos considerar vários valores de $b$ simultaneamente, podemos fazer o sequinte.

Fixe $\delta>0$ e sejam $\delta_i=\nicefrac{\delta}{2^i}$ com $i\in\mathds{N}$. Então $\sum_1^\infty \delta_i=\delta$.

Consideramos $\mathcal{L}_b$ para $b\in\mathds{Z}^{\geq}$. Aplicando o teorema \autoref{teo:pac} para $\mathcal{L}_b$ e $\delta_i$, temos que, com $h\in\mathcal{L}_b$ e com probabilidade pelo menos $1-\delta_i$
\begin{align*}
  \mathrm{err}_\mathcal{D}\left(h\vphantom{1j}\right) &\leq \mathrm{err}_\mathrm{S}\left(h\vphantom{1j}\right) + \sqrt{\frac{1}{2\cdot\left|\mathrm{S}\vphantom{1j}\right|}\cdot\left(i\cdot\log2 + \log\nicefrac{2}{\delta_i}\vphantom{1j}\right)}. \\
                                  &= \mathrm{err}_\mathrm{S}\left(h\vphantom{1j}\right) + \sqrt{\frac{1}{2\cdot\left|\mathrm{S}\vphantom{1j}\right|}\cdot\left(i\cdot\log4 + \log\nicefrac{2}{8}\vphantom{1j}\right)}.
\end{align*}

Concluímos que, com probabilidade pelo menos $1-\delta$,
\[
  \mathrm{err}_\mathcal{D}\left(h\vphantom{1j}\right) \leq = \mathrm{err}_\mathrm{S}\left(h\vphantom{1j}\right) + \sqrt{\frac{1}{2\cdot\left|\mathrm{S}\vphantom{1j}\right|}\cdot\left(\mathrm{size}\left(h\vphantom{1j}\right)\cdot\log4 + \log\nicefrac{2}{8}\vphantom{1j}\right)}.
\]

Podemos agora minimizar o todo direito variando $h\in\mathcal{H}$
%endregion

%region decision trees
\subsection{Árvores de decisão}

\textit{Árvores de decisão} são algoritmos bastante comuns em ML. Mesmo sendo provado que encontrar uma árvore ótima (com menor altura) dado o conjunto de treinamento $\mathrm{S}$ seja NP-difícil, existem diversas heurísticas usadas na prática. Uma biblioteca muito comumente usada para construção de árvores de decisão é a Scikit-learn, disponível em <\href{https://scikit-learn.org/stable/modules/tree.html}{https://scikit-learn.org/stable/modules/tree.html}>. Modelos baseados em árvores hoje atingem o estado da arte para dados tabulares, notavelmente tanto boosting trees como XGBoost e LightGBM, quanto árvores aleatórias de regressão como PRIM, MARS e CART.

\begin{fato}
  Obter uma menor $T$ tal que $\mathrm{err}_\mathrm{S}\left(T\vphantom{1j}\right)=0$ é NP-difícil.
\end{fato}

Suponha que $\mathcal{X}=\left\{0,\ 1\right\}^d$ e que $c^\star$ é uma função booleana (ou circuito lógico) das features. Seja $T$ uma árvore construída por algoritmo a partir de $\mathrm{S}$ com $k$ nós internos. Essa árvore pode ser descrita com $O\left(k\cdot\log d\right)$ bits, considerando a indução:
\begin{enumerate}
  \item $O\left(\lg d\right)$ para descrever a feature na raiz;
  \item $O\left(1\right)$ para indicar se um nó é folha;
  \item $O\left(\left(k-1\right)\cdot\log d\right)$ para descrever a subárvore esquerda e direita se nõa forem folhas.
\end{enumerate}

Assim, pelo teorema \autoref{teo:navalha_de_occam}, nós podemos confiar que o erro de generalização é baixo se conseguirmos criar uma árvore com no máximo $\eps\cdot\nicefrac{\left|\mathrm{S}\vphantom{1j}\right|}{\log d}$ nós.

\begin{figure}
  \label{fig:arvore_de_decisao}
  \begin{tikzpicture}[
    auto, thick,
    node/.style={draw, circle, thick, text centered, 
    minimum height=0.50cm, minimum width=0.50cm},
    star/.style={draw, diamond, thick, text centered, 
    minimum height=0.50cm, minimum width=0.50cm},
    block/.style={draw, thick, text centered, 
    minimum height=0.50cm, minimum width=0.50cm},
    title/.style={draw=none, circle, thick, text centered, 
    minimum height=0.50cm, minimum width=0.50cm},
    every loop/.style={}
    ]
    \node[node]   (x2)                                        {$x_2$};
    \node[node]   (x1)  [below=0.75 of x2, xshift=-2.00cm]    {$x_1$};
    \node[node]   (x3)  [below=0.75 of x2, xshift= 2.00cm]    {$x_3$};
    \node[node]   (x4)  [below=0.75 of x3, xshift= 1.00cm]    {$x_1$};
    
    \node[block]  (y1)  [below=0.75 of x1, xshift=-1.00cm]    {$+$};
    \node[block]  (y2)  [below=0.75 of x1, xshift= 1.00cm]    {$-$};
    \node[block]  (y3)  [below=0.75 of x3, xshift=-1.00cm]    {$+$};
    \node[block]  (y4)  [below=0.75 of x4, xshift=-1.00cm]    {$-$};
    \node[block]  (y5)  [below=0.75 of x4, xshift= 1.00cm]    {$+$};
    
    \path[->]
    (x2)  edge  node[above left]  {$0$}  (x1)
    (x2)  edge  node[above right] {$1$}  (x3)
    (x1)  edge  node[above left]  {$0$}  (y1)
    (x1)  edge  node[above right] {$1$}  (y2)
    (x3)  edge  node[above left]  {$0$}  (y3)
    (x3)  edge  node[above right] {$1$}  (x4)
    (x4)  edge  node[above left]  {$0$}  (y4)
    (x4)  edge  node[above right] {$1$}  (y5)
    ;
  \end{tikzpicture}
\end{figure}

\begin{exemplo}
  Considere a árvore de decisão da figura \autoref{fig:arvore_de_decisao}.

  Sua fórmula booleana equivalente é $\overline{x_1}\overline{x_2}\lor x_2\overline{x_1}\lor x_1x_2x_3$.

  Como uma hipótese sobre os dados, pode ser descrita da seguinte forma linguagem recursiva:
  {
    \delimitershortfall=-1pt
    $\mathcal{L}$: 
    $\left(x_2
            \left(x_1
                  \left(+\vphantom{1j}\right)
                  \left(-\vphantom{1j}\right)
            \vphantom{1j}\right)
            \left(x_3
                  \left(+\vphantom{1j}\right)
                  \left(x_1
                      \left(-\vphantom{1j}\right)
                      \left(+\vphantom{1j}\right)
                  \vphantom{1j}\right)
            \vphantom{1j}\right)
      \vphantom{1j}\right)$
  }

  Usando como alfabeto $\left\{1,\ \ldots,\ d\vphantom{1j}\right\}\cup\left\{\text{`('},\ \text{`)'},\ \text{`+'},\ \text{`-'}\vphantom{1j}\right\}$, temos $\left\lceil\lg\left(d+4\vphantom{1j}\right)\vphantom{1j}\right\rceil$ bits por símbolo.
\end{exemplo}

\begin{exercicio}
  Seja $f(k)$ o número de símbolos que precisamos para representar uma árvore de decisão com $k$ nós externos em $\mathcal{L}$. Prove que
  \[
    f(k) = 3\cdot\left(2\cdot k-1\vphantom{1j}\right),\ k\geq 1
  \]

  Representação de uma árvore de decisão com $k$ nós externos:
  \[
    3\cdot\left(2\cdot k-1\vphantom{1j}\right)\cdot\left\lceil\lg\left(d+4\vphantom{1j}\right)\vphantom{1j}\right\rceil = \mathcal{O}\left(k\cdot\log d\vphantom{1j}\right) \text{bits}
  \]
\end{exercicio}
\begin{resolucao}
  Os $k$ nós externos contribuem com $3$ símbolos cada: `(+)' ou `(-)'.

  Os $k-1$ nós internos contribuem com $3$ símbolos cada: `(x' e `')'

  Resultado: $3\cdot k + 3\cdot\left(k-1\vphantom{1j}\right) = 3\cdot\left(2\cdot k-1\vphantom{1j}\right)$.

  O fator $\cdot\left\lceil\lg\left(d+4\vphantom{1j}\right)\vphantom{1j}\right\rceil$ é pela quantidade mínima de bits para representar o alfabeto.
\end{resolucao}

Dado $\mathrm{S}\subseteq\left\{0,\ 1\vphantom{1j}\right\}^d$, como obtemos uma Árvore de Decisão $T$ com $\mathrm{err}_\mathrm{S}\left(T\vphantom{1j}\right)=0$?

\begin{exercicio}
  Fácil obter uma $T$ com $\leq2\cdot\left|\mathrm{S}\vphantom{1j}\right|$ nós externos.
\end{exercicio}
\begin{resolucao}
  Uma árvore balanceada com $2^d=\left|\mathrm{S}\vphantom{1j}\right|$ nós externos é capaz de estilhaçar $\mathrm{S}\subseteq\left\{0,\ 1\vphantom{1j}\right\}^d$
\end{resolucao}

Assim
\[
  \mathrm{size}\left(T\vphantom{1j}\right) = \mathcal{O}\left(\left|\mathrm{S}\vphantom{1j}\right|\log d\vphantom{1j}\right).
\]

Se conseguimos $T$ com \autoref{teo:navalha_de_occam}
\[
  \mathrm{size}\left(T\vphantom{1j}\right) \leq \frac{\eps}{2\cdot\log 2} \left|\mathrm{S}\vphantom{1j}\right|
\]

e $\left|\mathrm{S}\vphantom{1j}\right|\geq\frac{2}{\eps}\cdot\log\nicefrac{1}{\delta}$, então com prob. $\geq 1-\delta$,
\begin{align}
  \mathrm{err}_\mathcal{D}\left(T\vphantom{1j}\right) &\leq \frac{\mathrm{size}\left(T\vphantom{1j}\right)\cdot\log2 + \log\nicefrac{1}{\delta}}{\left|\mathrm{S}\vphantom{1j}\right|}  \\
                                  &\leq \frac{\eps}{2} + \frac{\eps}{2} = \eps
\end{align}

Podemos deduzir algo análogo para o \autoref{cor:convergencia_uniforme_bits}.
%endregion

%region Iterative dichotomizer
\subsection{Heurística ID3}

A deurística \textit{Iterative Dichotomizer 3} é um método guloso de construção de árvores de decisão. A cada nó, escolhe-se a feature com maior \textit{information gain}, isto é, que melhor separa os dados em um único passo, até que numa subdivisão ocorram apenas pontos negativos ou positivos. Esse algoritmo converge para um ótimo local, que em geral pode ser arbitrariamente pior (altura da árvore) que o ótimo global, porém existem alguns resultados extremais com relação à \textit{informação mútua} <\href{https://en.wikipedia.org/wiki/Mutual\_information}{https://en.wikipedia.org/wiki/Mutual\_information}>.

\begin{definicao}
  Considere a partição $\mathrm{S}=\mathrm{S}^+\cup\mathrm{S}^-$ de instâncias positivas e negativas.

  Seja também a indicação $\mathrm{S}_{x_i=0}\vcentcolon=\left\{s\in \mathrm{S}\colon\ x_i=0\vphantom{1j}\right\}$.
  
  A entropia binária é definida como
  \[
    \mathrm{H}\left(p\vphantom{1j}\right) = \mathrm{H}_2\left(p\vphantom{1j}\right) \vcentcolon= p\cdot\lg\nicefrac{1}{p} + q\cdot\lg\nicefrac{1}{q},
  \]
  onde $p+q=1$ e $0\leq 0\leq1$, tomando como convenção $0\cdot\log\nicefrac{1}{0}=0\cdot\log0=0$.

  De forma similar, definem-se as seguintes notações:
  \[
    \mathrm{H}\left(\mathrm{S}\vphantom{1j}\right) = \mathrm{H}\left(\nicefrac{\left|\mathrm{S}^+\vphantom{1j}\right|}{\left|\mathrm{S}\vphantom{1j}\right|}\vphantom{1j}\right),
  \]
  e
  \[
    \mathrm{H}\left(\mathrm{S}\,\middle|\, x_i\vphantom{1j}\right) = \frac{\mathrm{S}_{x_i=0}}{\mathrm{S}}\cdot\mathrm{H}\left(\mathrm{S}_{x_i=0}\vphantom{1j}\right) + \frac{\mathrm{S}_{x_i=1}}{\mathrm{S}}\cdot\mathrm{H}\left(\mathrm{S}_{x_i=1}\vphantom{1j}\right).
  \]
\end{definicao}

\begin{figure}
  \label{fig:information_gain}
  \begin{tikzpicture}[
    auto, thick,
    node/.style={draw, circle, thick, text centered, 
    minimum height=0.50cm, minimum width=0.50cm},
    star/.style={draw, diamond, thick, text centered, 
    minimum height=0.50cm, minimum width=0.50cm},
    block/.style={draw, thick, text centered, 
    minimum height=0.50cm, minimum width=0.50cm},
    title/.style={draw=none, circle, thick, text centered, 
    minimum height=0.50cm, minimum width=0.50cm},
    every loop/.style={}
    ]
    \node[node]   (x1)                                        {$x_1$};
    
    \node[block]  (y1)  [below=0.75 of x1, xshift=-1.00cm]    {$\mathrm{S}_{x_i=0}$};
    \node[block]  (y2)  [below=0.75 of x1, xshift= 1.00cm]    {$\mathrm{S}_{x_i=1}$};
    
    \path[->]
      (x1)  edge  node[above left]  {$0$}  (y1)
      (x1)  edge  node[above right] {$1$}  (y2)
    ;
  \end{tikzpicture}
\end{figure}

\begin{definicao}
  A heurística de information gain --- ilustrada em \autoref{fig:information_gain} --- é a escolha de $x_i$ para maximizar o ganho de informação.
  \[
    \mathrm{IG}\left(i\vphantom{1j}\right) \vcentcolon= \mathrm{H}\left(S\vphantom{1j}\right) - \mathrm{H}\left(\mathrm{S}\,\middle|\, x_i\vphantom{1j}\right).
  \]
\end{definicao}
%endregion
